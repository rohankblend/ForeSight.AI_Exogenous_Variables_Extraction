{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime, timezone\n",
    "import pytz\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dictionary for converting month and quarter data to date in DD-MM-YYYY format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {'Jan' : '01-01', 'Feb' : '01-02', 'Mar' : '01-03', 'Apr' : '01-04', 'May' : '01-05', 'Jun': '01-06',\n",
    "'Jul' : '01-07', 'Aug' : '01-08', 'Sep' : '01-09', 'Oct' : '01-10', 'Nov' : '01-11', 'Dec' : '01-12'}\n",
    "qtr_dict = {'Q1' : '01-01', 'Q2' : '01-04', 'Q3' : '01-07', 'Q4' : '01-10'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eastern_tz = pytz.timezone('US/Eastern')\n",
    "utc_now = datetime.now(pytz.utc)\n",
    "eastern_now = utc_now.astimezone(eastern_tz)\n",
    "# current_date = datetime.now(timezone.utc).strftime('%d-%m-%Y')\n",
    "current_date = eastern_now.date().strftime('%d-%m-%Y')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for scraping website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(url):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\n",
    "        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.51\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "    return driver"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for getting date in 'DD-MM-YYYY' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date_string):\n",
    "    if date_string[:3] in month_dict.keys():\n",
    "        date_val =month_dict[date_string[:3]] + '-' + date_string[-5:-1]\n",
    "    else:\n",
    "        date_val =qtr_dict[date_string[:2]] + '-' + date_string[-5:-1]\n",
    "    return date_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Feature data with URLs and HTML Elements to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('Feature_list.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract website data along with error URLs if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(df):\n",
    "    values = {}\n",
    "    dates = {}\n",
    "    error_urls=[]\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            print(row['Feature'])\n",
    "            driver = scrape_data(row['URL'])\n",
    "            try:\n",
    "                value_element = driver.find_elements(By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]')[0]\n",
    "            except StaleElementReferenceException:\n",
    "                driver.refresh()\n",
    "                value_element = WebDriverWait(driver, 10).until(\\\n",
    "                EC.presence_of_all_elements_located((By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]')))[0]\n",
    "            if not isinstance(row['snap_element_value'],str) and math.isnan(row['snap_element_value']):\n",
    "                values[row['Feature']] = value_element.text.replace('$', '')\n",
    "            else:\n",
    "                values[row['Feature']] = value_element.find_element(By.XPATH, f'.//span[@class=\"{row[\"snap_element_value\"]}\"]').text.replace('$', '')\n",
    "            if not isinstance(row['snap_element_max_date'],str) and math.isnan(row['snap_element_max_date']):\n",
    "                dates[row['Feature']] = current_date\n",
    "            else:\n",
    "                try:\n",
    "                    date_element = driver.find_elements(By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]')[0]\n",
    "                    date_string = date_element.find_element(By.XPATH, f'.//span[@class=\"{row[\"snap_element_max_date\"]}\"]').text\n",
    "                except StaleElementReferenceException:\n",
    "                    driver.refresh()\n",
    "                    date_element = WebDriverWait(driver, 10).until(\\\n",
    "                        EC.presence_of_all_elements_located((By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]')))[0]\n",
    "                    date_string = date_element.find_element(By.XPATH, f'.//span[@class=\"{row[\"snap_element_max_date\"]}\"]').text\n",
    "                dates[row['Feature']] =  get_date(date_string)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error_urls.append(row['URL']) \n",
    "    return values, dates, error_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNRATE\n",
      "CPI\n",
      "GDP\n",
      "FED_GRANTS\n",
      "S&P500\n",
      "GOLD_PRICE\n",
      "CRUDE_PRICE\n"
     ]
    }
   ],
   "source": [
    "res_values, res_dates, error_urls = get_attributes(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('exog_variables.csv', dayfirst=True, index_col=0)\n",
    "data_df.loc[len(data_df), 'DATE'] = current_date\n",
    "for key, value in res_dates.items():\n",
    "    if pd.to_datetime(value, dayfirst=True) < pd.to_datetime(data_df['DATE'].iloc[-1], dayfirst=True):\n",
    "        selected = pd.to_datetime(data_df['DATE'], dayfirst=True) >= pd.to_datetime(value, dayfirst=True)\n",
    "        data_df.loc[selected, key] = res_values[key]      \n",
    "    else:\n",
    "        data_df.loc[len(data_df)-1, key] = res_values[key]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output dataframe with ffill for missing values for any features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['DATE'] = pd.to_datetime(data_df['DATE'], dayfirst=True)\n",
    "df_daily = data_df.set_index('DATE').resample('D').asfreq()\n",
    "df_daily.reset_index(inplace=True)\n",
    "df_daily.loc[:, data_df.columns != 'COVID_STRINGENCY_INDEX'] = df_daily.loc[:, data_df.columns != 'COVID_STRINGENCY_INDEX'].fillna(method='ffill')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.to_csv('exog_variables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = {}\n",
    "json_dict['Update_date'] = current_date\n",
    "json_dict['Error_URLs'] = error_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('run_summary.json', 'w') as f:\n",
    "    json.dump(json_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
