{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pytz\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dictionary for converting month and quarter data to date in DD-MM-YYYY format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {'Jan' : '01-01', 'Feb' : '01-02', 'Mar' : '01-03', 'Apr' : '01-04', 'May' : '01-05', 'Jun': '01-06',\n",
    "'Jul' : '01-07', 'Aug' : '01-08', 'Sep' : '01-09', 'Oct' : '01-10', 'Nov' : '01-11', 'Dec' : '01-12'}\n",
    "qtr_dict = {'Q1' : '01-01', 'Q2' : '01-04', 'Q3' : '01-07', 'Q4' : '01-10'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get current date as per US Western TZ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# western_tz = pytz.timezone('US/Alaska')\n",
    "utc_now = datetime.now(pytz.utc) - timedelta(days=1)\n",
    "# western_now = utc_now.astimezone(western_tz) \n",
    "# current_date = datetime.now(timezone.utc).strftime('%d-%m-%Y')\n",
    "# current_date = western_now.date().strftime('%d-%m-%Y')\n",
    "current_date = utc_now.date().strftime('%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a Chrome Driver instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = ChromeDriverManager().install()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the User Agent and updating Chrome Driver Options parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--incognito\")\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "driver = webdriver.Chrome(service=Service(chrome_driver_path), options=options)\n",
    "agent = driver.execute_script(\"return navigator.userAgent\")\n",
    "options.add_argument(f\"user-agent={agent}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for scraping website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(url, chrome_driver_path, options):  \n",
    "    driver = webdriver.Chrome(service=Service(chrome_driver_path), options=options)\n",
    "    driver.get(url)\n",
    "    return driver"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for getting date in 'DD-MM-YYYY' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date_string):\n",
    "    if date_string[:3] in month_dict.keys():\n",
    "        date_val =month_dict[date_string[:3]] + '-' + date_string[-5:-1]\n",
    "    else:\n",
    "        date_val =qtr_dict[date_string[:2]] + '-' + date_string[-5:-1]\n",
    "    return date_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for getting feature data directly from a URL with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    # Get last one week data for the feature\n",
    "    rows = response.text.split('\\r\\n')[-8:-1]\n",
    "    values = []\n",
    "    dates = []\n",
    "    for row in rows:\n",
    "        values.append(row.split(' ')[-1])\n",
    "        dates.append(row.split(' ')[0])\n",
    "    return values, dates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Feature data with URLs and HTML Elements to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('Feature_list.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract website data along with error URLs if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(df, chrome_driver_path, options):\n",
    "    values = {}\n",
    "    dates = {}\n",
    "    error_urls=[]\n",
    "    for _, row in df.iterrows():\n",
    "        if not isinstance(row['div_element'],str) and math.isnan(row['div_element']):\n",
    "            try:\n",
    "                print(row['Feature'])\n",
    "                values[row['Feature']], dates[row['Feature']] = get_data_from_url(row['URL'])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                error_urls.append(row['URL']) \n",
    "        else:\n",
    "            try:\n",
    "                print(row['Feature'])\n",
    "                sub_ele = row['sub_element_type']\n",
    "                # print(sub_ele)           \n",
    "                driver = scrape_data(row['URL'], chrome_driver_path, options)\n",
    "                try:\n",
    "                    if not isinstance(sub_ele,str) and math.isnan(sub_ele):\n",
    "                        values[row['Feature']] = driver.find_elements(By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]')[0].text.replace('$', '').replace(',','')\n",
    "                    else:\n",
    "                        if sub_ele == 'bdo':\n",
    "                            values[row['Feature']] = driver.find_elements(By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]')[0].find_element(By.XPATH, f'.//bdo[@class=\"{row[\"sub_element_value\"]}\"]').text.replace('$', '').replace(',','')\n",
    "                        else :\n",
    "                            values[row['Feature']] = driver.find_elements(By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]')[0].find_element(By.XPATH, f'.//span[@class=\"{row[\"sub_element_value\"]}\"]').text.replace('$', '').replace(',','')\n",
    "                except StaleElementReferenceException:\n",
    "                    driver.refresh()\n",
    "                    if not isinstance(sub_ele,str) and math.isnan(sub_ele):\n",
    "                        values[row['Feature']] = WebDriverWait(driver, 10).until(\\\n",
    "                            EC.presence_of_all_elements_located((By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]'))[0].text.replace('$', '')).replace(',','')\n",
    "                    else:\n",
    "                        if sub_ele == 'bdo':\n",
    "                            values[row['Feature']] = WebDriverWait(driver, 10).until(\\\n",
    "                                EC.presence_of_all_elements_located((By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]'))[0].find_element(By.XPATH, f'.//bdo[@class=\"{row[\"sub_element_value\"]}\"]').text.replace('$', '')).replace(',','')\n",
    "                        else:\n",
    "                            values[row['Feature']] = WebDriverWait(driver, 10).until(\\\n",
    "                                EC.presence_of_all_elements_located((By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]'))[0].find_element(By.XPATH, f'.//span[@class=\"{row[\"sub_element_value\"]}\"]').text.replace('$', '')).replace(',','')\n",
    "                            \n",
    "                if not isinstance(row['sub_element_max_date'],str) and math.isnan(row['sub_element_max_date']):\n",
    "                    dates[row['Feature']] = current_date\n",
    "                else:\n",
    "                    try:\n",
    "                        if sub_ele == 'bdo':\n",
    "                            date_string = driver.find_elements(By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]')[0].find_element(By.XPATH, f'.//bdo[@class=\"{row[\"sub_element_max_date\"]}\"]').text\n",
    "                        else:\n",
    "                            date_string = driver.find_elements(By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]')[0].find_element(By.XPATH, f'.//span[@class=\"{row[\"sub_element_max_date\"]}\"]').text\n",
    "                    except StaleElementReferenceException:\n",
    "                        driver.refresh()\n",
    "                        if sub_ele == 'bdo':\n",
    "                            date_string = WebDriverWait(driver, 30).until(\\\n",
    "                                EC.presence_of_all_elements_located((By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]'))[0].find_element(By.XPATH, f'.//bdo[@class=\"{row[\"sub_element_max_date\"]}\"]').text)\n",
    "                        else:\n",
    "                            date_string = WebDriverWait(driver, 30).until(\\\n",
    "                                EC.presence_of_all_elements_located((By.XPATH, f'//div[@class=\"{row[\"div_element\"]}\"]'))[0].find_element(By.XPATH, f'.//span[@class=\"{row[\"sub_element_max_date\"]}\"]').text)\n",
    "                    dates[row['Feature']] =  get_date(date_string)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                error_urls.append(row['URL']) \n",
    "    return values, dates, error_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRUDE_PRICE\n",
      "S&P500\n",
      "UNRATE\n",
      "CPI\n",
      "GDP\n",
      "FED_GRANTS\n",
      "GOLD_PRICE\n"
     ]
    }
   ],
   "source": [
    "res_values, res_dates, error_urls = get_attributes(feature_df, chrome_driver_path, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('exog_variables.csv', dayfirst=True, index_col=0)\n",
    "if pd.to_datetime(data_df['DATE'].iloc[-1], dayfirst=True, format='mixed') < pd.to_datetime(current_date, dayfirst=True, format='mixed'):\n",
    "    data_df.loc[len(data_df), 'DATE'] = current_date\n",
    "for key, value in res_dates.items():\n",
    "    if isinstance(value, list):\n",
    "        for i, date in enumerate(value):\n",
    "            if pd.to_datetime(date, dayfirst=True, format='mixed') < pd.to_datetime(data_df['DATE'].iloc[-1], dayfirst=True, format='mixed'):\n",
    "                selected = pd.to_datetime(data_df['DATE'], dayfirst=True, format='mixed') >= pd.to_datetime(date, dayfirst=True, format='mixed')\n",
    "                data_df.loc[selected, key] = res_values[key][i]      \n",
    "            else:\n",
    "                data_df.loc[len(data_df)-1, key] = res_values[key][i]\n",
    "    else:\n",
    "        if pd.to_datetime(value, dayfirst=True, format='mixed') < pd.to_datetime(data_df['DATE'].iloc[-1], dayfirst=True, format='mixed'):\n",
    "            selected = pd.to_datetime(data_df['DATE'], dayfirst=True, format='mixed') >= pd.to_datetime(value, dayfirst=True, format='mixed')\n",
    "            data_df.loc[selected, key] = res_values[key]      \n",
    "        else:\n",
    "            data_df.loc[len(data_df)-1, key] = res_values[key]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output dataframe with ffill for missing values for any features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['DATE'] = pd.to_datetime(data_df['DATE'], dayfirst=True, format='mixed')\n",
    "df_daily = data_df.set_index('DATE').resample('D').asfreq()\n",
    "df_daily.reset_index(inplace=True)\n",
    "\n",
    "df_daily[df_daily.select_dtypes(['object']).columns] = df_daily.select_dtypes(['object']).astype(float)\n",
    "df_daily = df_daily.replace('.', '')\n",
    "\n",
    "df_daily.loc[:, data_df.columns != 'COVID_STRINGENCY_INDEX'] = df_daily.loc[:, data_df.columns != 'COVID_STRINGENCY_INDEX'].fillna(method='ffill')\n",
    "\n",
    "# df_daily[df_daily.select_dtypes(['object']).columns] = df_daily.select_dtypes(['object']).astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.to_csv('exog_variables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = {}\n",
    "json_dict['Update_date'] = current_date\n",
    "json_dict['Error_URLs'] = error_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('run_summary.json', 'w') as f:\n",
    "    json.dump(json_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
